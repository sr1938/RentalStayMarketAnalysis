
export mysql_connector_path=/home/hadoop/mysql-connector-java-8.0.23.jar

export spark_classpath=$spark_classpath:$mysql_connector_path

pyspark --jars $mysql_connector_path


from pyspark.sql import SparkSession

jdbc_url = "jdbc:mysql://database-1.cnp0t9ojtoc4.us-east-1.rds.amazonaws.com:3306/bigpro"

jdbc_pro = {"user":"admin","password":"12345678","driver":"com.mysql.jdbc.Driver"}


#to read data from rds 

df2 = spark.read.jdbc(url=jdbc_url,table="latestdata",properties=jdbc_pro)


# to write data into s3 bucket from emr pyspark :-

bucket_path = "s3://desti01bucket/latest/"

df2.write.csv(bucket_path ,mode="overwrite",header=True)

df2.select("host_verifications").show()

# to Merged dataset:-

df4 = spark.read.format('csv').options(sep=",", escape='"', mode="PERMISSIVE", header=True, multiLine=True).load('s3://source01bucket/project/total_data.csv')



column_names = [
    "id", "name", "host_name", "host_response_time","host_listings_count", "host_verifications", 
    "host_identity_verified", "neighbourhood","city","latitude", "longitude", 
    "property_type", "room_type", "accommodates", "bathrooms", "bedrooms", "beds", "amenities", 
    "price", "security_deposit", "guests_included", "extra_people", 
    "availability_30", "availability_60", "availability_90", "availability_365","number_of_reviews", 
    "review_scores_rating", "review_scores_accuracy", "review_scores_cleanliness", 
    "review_scores_checkin", "review_scores_communication", "review_scores_location", 
    "review_scores_value", "instant_bookable", "cancellation_policy", "month", 
    "minimum_minimum_nights","maximum_maximum_nights","calculated_host_listings_count"
]



>>> rdstdata=df2.select(column_names)  
>>> s3data=df4.select(column_names)
>>> merged_df = rdsdata.union(s3data)
>>> merged_df.count()
913973



