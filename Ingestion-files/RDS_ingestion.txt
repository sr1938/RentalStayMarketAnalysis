# make connection between emr and rds

--> firstly download  "mysql-connector-java-8.0.23.jar" file and uplode it on local file system of cluter


-->> on emr runs following commands

export mysql_connector_path=/home/hadoop/mysql-connector-java-8.0.23.jar

export spark_classpath=$spark_classpath:$mysql_connector_path

pyspark --jars $mysql_connector_path


from pyspark.sql import SparkSession

jdbc_url = "jdbc:mysql://group4.c5enejajetyi.us-east-1.rds.amazonaws.com:3306/group4"

jdbc_pro = {"user":"admin","password":"123456789","driver":"com.mysql.jdbc.Driver"}


--------------------------------------------------------
# To read data from rds


df2 = spark.read.jdbc(url=jdbc_url,table="rds",properties=jdbc_pro)

------------------------------------------------------

# To write data to s3 Datalake 

df2.coalesce(1).write \
    .option("header", "True") \
    .option("multiline", True) \
    .parquet("s3://group4-raw-data-zone/rdsdata.parquet")

d=df2.select("price").distinct()
d.show()


-------------------------------------------------------------

# To read data from s3 datalake

rds2 = spark.read.parquet('s3://group4-raw-data-zone/rdsdata.parquet/part-00000-39d6cd9d-9326-4fb5-b597-dca63cd9388a-c000.snappy.parquet')




d=rds2.select("amenities").distinct()
d.show()
